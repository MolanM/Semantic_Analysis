{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998ef0a9",
   "metadata": {
    "gather": {
     "logged": 1651664094494
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from random import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd526a9a",
   "metadata": {
    "gather": {
     "logged": 1651664120751
    }
   },
   "outputs": [],
   "source": [
    "with open('encoded_c1_incels.pkl', 'rb') as outp:\n",
    "    rr = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24d1873",
   "metadata": {
    "gather": {
     "logged": 1651664120993
    }
   },
   "outputs": [],
   "source": [
    "with open('encoded_baseline.pkl', 'rb') as outp:\n",
    "    ba = pickle.load(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b886ae6d",
   "metadata": {
    "gather": {
     "logged": 1651664121161
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 84)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rr),len(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f08839",
   "metadata": {
    "gather": {
     "logged": 1651664121296
    }
   },
   "outputs": [],
   "source": [
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731dc1b0",
   "metadata": {
    "gather": {
     "logged": 1651664121436
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "149\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# test set: 500 class 0, 500 class 1\n",
    "#in chunks of 50, 500 = 50*10\n",
    "chunks = 10\n",
    "\n",
    "ind_b = [i for i in range(len(ba))]\n",
    "ind_r = [i for i in range(len(rr))]\n",
    "shuffle(ind_b)\n",
    "shuffle(ind_r)\n",
    "\n",
    "\n",
    "train0 = [ba[i] for i in ind_b[:-chunks]]\n",
    "train1 = [rr[i] for i in ind_r[:-chunks]]\n",
    "\n",
    "test0 = [ba[i] for i in ind_b[-chunks:]]\n",
    "test1 = [rr[i] for i in ind_r[-chunks:]]\n",
    "\n",
    "val0 = test0[:len(test0)//2]\n",
    "test0 = test0[len(test0)//2:]\n",
    "\n",
    "val1 = test1[:len(test1)//2]\n",
    "test1 = test1[len(test1)//2:]\n",
    "\n",
    "for i in (train0, train1, test0, test1, val0, val1): print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd417917",
   "metadata": {
    "gather": {
     "logged": 1651664121574
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(ba,rr):\n",
    "    cl0 = tf.keras.backend.concatenate(\n",
    "        ba,\n",
    "        axis=0\n",
    "    )\n",
    "    cl1 = tf.keras.backend.concatenate(\n",
    "        rr,\n",
    "        axis=0\n",
    "    )\n",
    "    train = tf.keras.backend.concatenate(\n",
    "        [cl0,cl1],\n",
    "        axis=0\n",
    "    )\n",
    "    y = np.concatenate([np.zeros(cl0.shape[0]), np.ones(cl1.shape[0])]).astype(int)\n",
    "\n",
    "    #shufle\n",
    "    ind_list = [i for i in range(y.shape[0])]\n",
    "    shuffle(ind_list)\n",
    "    train_new = np.array([train[i] for i in ind_list])\n",
    "    y_new = np.array([y[i] for i in ind_list])\n",
    "\n",
    "    #one-hot\n",
    "    train_y = np.zeros((y_new.size, y_new.max()+1))\n",
    "    train_y[np.arange(y_new.size),y_new] = 1\n",
    "    train_y.shape\n",
    "    \n",
    "    return(train_new, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2744e3",
   "metadata": {
    "gather": {
     "logged": 1651664148415
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train =  preprocess(train0, train1)\n",
    "X_val, y_val = preprocess(val0,val1)\n",
    "X_test, y_test =  preprocess(test0, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37a47e5",
   "metadata": {
    "gather": {
     "logged": 1651664148546
    }
   },
   "outputs": [],
   "source": [
    "def create_model(size = 10):\n",
    "    \n",
    "    inputs = keras.Input(shape=(1024,))\n",
    "    \n",
    "    for i in range(size,1,-1):\n",
    "        if i == size:\n",
    "            x = layers.Dense(2**size, activation=\"relu\")(inputs)\n",
    "        else:\n",
    "            x = layers.Dense(int(0.7*(2**(i+1))), activation=\"relu\")(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "            x = layers.Dense(2**i, activation=\"relu\")(x)\n",
    "    \n",
    "\n",
    "\n",
    "    outputs = layers.Dense(2)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a268c1a",
   "metadata": {
    "gather": {
     "logged": 1651664151771
    }
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a92d3429",
   "metadata": {
    "gather": {
     "logged": 1651664152159
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4893dc",
   "metadata": {},
   "source": [
    "## Ensamble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94638711",
   "metadata": {
    "gather": {
     "logged": 1651664152851
    }
   },
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a538bfdc",
   "metadata": {
    "gather": {
     "logged": 1651664152982
    }
   },
   "outputs": [],
   "source": [
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        #print(yhat.shape)\n",
    "        # stack predictions into [rows, members, probabilities]d\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, yhat))\n",
    "    return stackX.reshape(stackX.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eefc48cf",
   "metadata": {
    "gather": {
     "logged": 1651664153117
    }
   },
   "outputs": [],
   "source": [
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit standalone model\n",
    "    \n",
    "    #model = LogisticRegression()\n",
    "    model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    model.fit(stackedX, inputy.argmax(axis = -1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15f9230",
   "metadata": {
    "gather": {
     "logged": 1651664153255
    }
   },
   "outputs": [],
   "source": [
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206085b5",
   "metadata": {
    "gather": {
     "logged": 1651664153405
    }
   },
   "outputs": [],
   "source": [
    "#early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eba17c6",
   "metadata": {
    "gather": {
     "logged": 1651664153557
    }
   },
   "outputs": [],
   "source": [
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    model = create_model(10)\n",
    "    model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"])\n",
    "    model.fit(trainX, trainy, batch_size=512, epochs=100,shuffle= True, validation_split=0.2, callbacks=[callback], verbose = 0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "968bd561",
   "metadata": {
    "gather": {
     "logged": 1651664153698
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    makedirs('new_models_50')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b1f8018",
   "metadata": {
    "gather": {
     "logged": 1651664405508
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved new_models_50/model_1.h5\n",
      ">Saved new_models_50/model_2.h5\n",
      ">Saved new_models_50/model_3.h5\n",
      ">Saved new_models_50/model_4.h5\n",
      ">Saved new_models_50/model_5.h5\n",
      ">Saved new_models_50/model_6.h5\n",
      ">Saved new_models_50/model_7.h5\n",
      ">Saved new_models_50/model_8.h5\n",
      ">Saved new_models_50/model_9.h5\n",
      ">Saved new_models_50/model_10.h5\n"
     ]
    }
   ],
   "source": [
    "n_members = 10\n",
    "for i in range(n_members):\n",
    "    # fit model\n",
    "    model = fit_model(X_train,y_train)\n",
    "    # save model\n",
    "    filename = 'new_models_50/model_' + str(i + 1) + '.h5'\n",
    "    model.save(filename)\n",
    "    print('>Saved %s' % filename)\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f495b68",
   "metadata": {
    "gather": {
     "logged": 1651664405657
    }
   },
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'new_models_50/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5979203b",
   "metadata": {
    "gather": {
     "logged": 1651664422384
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded new_models_50/model_1.h5\n",
      ">loaded new_models_50/model_2.h5\n",
      ">loaded new_models_50/model_3.h5\n",
      ">loaded new_models_50/model_4.h5\n",
      ">loaded new_models_50/model_5.h5\n",
      ">loaded new_models_50/model_6.h5\n",
      ">loaded new_models_50/model_7.h5\n",
      ">loaded new_models_50/model_8.h5\n",
      ">loaded new_models_50/model_9.h5\n",
      ">loaded new_models_50/model_10.h5\n",
      "Loaded 10 models\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "n_members = 10\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7fe1cf9",
   "metadata": {
    "gather": {
     "logged": 1651664428260
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.890\n",
      "Model Accuracy: 0.958\n",
      "Model Accuracy: 0.970\n",
      "Model Accuracy: 0.924\n",
      "Model Accuracy: 0.918\n",
      "Model Accuracy: 0.964\n",
      "Model Accuracy: 0.948\n",
      "Model Accuracy: 0.960\n",
      "Model Accuracy: 0.910\n",
      "Model Accuracy: 0.958\n",
      "Stacked Test Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "#on val set\n",
    "for model in members:\n",
    "    _, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Model Accuracy: %.3f' % acc)\n",
    "# fit stacked model using the ensemble\n",
    "\n",
    "model_s = fit_stacked_model(members, X_val, y_val)\n",
    "# evaluate model on test set\n",
    "\n",
    "yhat = stacked_prediction(members, model_s, X_val)\n",
    "acc = accuracy_score(y_val.argmax(axis = -1), yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1a5112d",
   "metadata": {
    "gather": {
     "logged": 1651664433841
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.906\n",
      "Model Accuracy: 0.990\n",
      "Model Accuracy: 0.990\n",
      "Model Accuracy: 0.914\n",
      "Model Accuracy: 0.924\n",
      "Model Accuracy: 0.986\n",
      "Model Accuracy: 0.972\n",
      "Model Accuracy: 0.986\n",
      "Model Accuracy: 0.940\n",
      "Model Accuracy: 0.984\n",
      "Stacked Test Accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "#on test set\n",
    "for model in members:\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Model Accuracy: %.3f' % acc)\n",
    "    \n",
    "# evaluate model on test set\n",
    "yhat = stacked_prediction(members, model_s, X_test)\n",
    "acc = accuracy_score(y_test.argmax(axis = -1), yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118fa098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "txt_gpu2",
   "language": "python",
   "name": "txt_gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
